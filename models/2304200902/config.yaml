model:
  dim_context: 256
  dim_embedding: 384
  dim_feedforward: 1536
  num_heads: 6
  num_layers: 6
  prob_dropout: 0.2
train:
  batch_size: 32
  epochs: 10
  eval_interval: 1
  eval_iters: 100
  learning_rate: 0.0001
  max_batches_per_epoch: 3000
